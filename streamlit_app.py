import streamlit as st
from openai import OpenAI
import traceback
import os
from dotenv import load_dotenv

st.set_page_config(page_title="ğŸ’¬ Chatbot", page_icon="ğŸ’¬")

# Load API key from chatgpt.env
load_dotenv("chatgpt.env")

# Title & description (ëª¨ë¸ ì„¤ëª…ì„ ì‹¤ì œ ì‚¬ìš© ëª¨ë¸ê³¼ ì¼ì¹˜)
st.title("ğŸ’¬ Chatbot")
st.write(
    "This chatbot uses OpenAI's **GPT-4o-mini** model. "
    "The OpenAI API key is automatically loaded from the local `chatgpt.env` file (variable: `OPENAI_API_KEY`). "
    "If the key is missing, you'll see a notice below."
)

# Sidebar: Chatbot self description
with st.sidebar:
    st.header("About this chatbot")
    st.markdown(
        """
        **ì´ ì±—ë´‡ì€ ì—¬í–‰ ì¶”ì²œì— íŠ¹í™”ëœ ë¹„ì„œì…ë‹ˆë‹¤.**\
        ìŠ¤ìŠ¤ë¡œë¥¼ ìœ ëª…í•œ ì—¬í–‰ ìœ íŠœë²„ë¡œ ì†Œê°œí•˜ê³ , ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§€ì—­ì„ ë°”íƒ•ìœ¼ë¡œ
        â€¢ ë³¼ê±°ë¦¬/ëª…ì†Œ\
        â€¢ í˜„ì§€ ë§›ì§‘\
        ì„ êµ¬ë¶„í•˜ì—¬ ê¹”ë”í•œ ë¦¬ìŠ¤íŠ¸ë¡œ ì œì•ˆí•©ë‹ˆë‹¤.

        íŠ¹ì§•
        - ì¹œê·¼í•˜ê³  ëª…í™•í•œ í†¤ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
        - í•µì‹¬ ì •ë³´(ì´ìœ , ìœ„ì¹˜/íŠ¹ì§•, íŒ)ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•©ë‹ˆë‹¤.
        - ì¤‘ë³µì„ í”¼í•˜ê³ , ì—¬í–‰ ë™ì„ ê¹Œì§€ ê³ ë ¤í•˜ë ¤ ë…¸ë ¥í•©ë‹ˆë‹¤.

        ì‚¬ìš© ë°©ë²•
        - ì˜ˆ: "ì˜¤ì‚¬ì¹´ 2ë°• 3ì¼ ë§›ì§‘ê³¼ ëª…ì†Œ ì¶”ì²œ" / "ì œì£¼ë„ ë¹„ ì˜¤ëŠ” ë‚  ê°ˆ ê³³" ë“±
        - ë” êµ¬ì²´ì ì¼ìˆ˜ë¡ ë§ì¶¤ ì¶”ì²œì´ ì¢‹ì•„ì§‘ë‹ˆë‹¤.
        """
    )

openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    st.info(
        "chatgpt.env íŒŒì¼ì— `OPENAI_API_KEY` ê°’ì„ ì„¤ì •í•œ ë’¤ ì•±ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.",
        icon="ğŸ—ï¸",
    )
    st.stop()

# Create client
client = OpenAI(api_key=openai_api_key)

# Chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Render history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Chat input
if prompt := st.chat_input("What is up?"):
    # 1) show user message immediately
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2) build messages with system prompt at the very front
    chat_messages = [
        {
            "role": "system",
            "content": (
                "ë„ˆëŠ” ìœ ëª…í•œ ì—¬í–‰ ìœ íŠœë²„ì•¼. "
                "ì…ë ¥ë°›ì€ ì§€ì—­ì˜ ì—¬í–‰ì§€ì™€ ë§›ì§‘ì„ ì¶”ì²œí•´ì¤˜. "
                "ì—¬í–‰ì§€ì™€ ë§›ì§‘ì„ ë‚˜ëˆ ì„œ ìˆ«ì ë§ë¨¸ë¦¬ë¥¼ ë„£ì–´ ì¶œë ¥í•´ì¤˜."
            ),
        },
        *st.session_state.messages,  # includes the latest user message
    ]

    # 3) call OpenAI with streaming + error handling
    with st.chat_message("assistant"):
        try:
            # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¡œ ì—´ë©´ ì—°ê²° ì •ë¦¬ê°€ ê¹”ë”í•©ë‹ˆë‹¤.
            stream = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=chat_messages,
                stream=True,
            )
            response_text = st.write_stream(stream)  # typewriter streaming
            # 4) save assistant message
            st.session_state.messages.append(
                {"role": "assistant", "content": response_text}
            )
        except Exception as e:
            st.error("âš ï¸ Error while generating a response. Check your API key, model access, or network.")
            with st.expander("Show error details"):
                st.code("".join(traceback.format_exception_only(type(e), e)))
